# ğŸ§  My Mind

## ğŸ¤– LLM-Powered PDF & Notes ETL Pipeline (Python)

<table>
  <tr>
    <td style="vertical-align: top; padding-right: 20px; width: 50%">

<strong>My Mind</strong> is a <strong>modular ETL pipeline</strong> and <strong>personal knowledge assistant</strong> designed to transform your entire information ecosystem into a <strong>searchable, LLM-augmented brain</strong>.

It <strong>ingests diverse sources</strong> such as <strong>PDFs (digital and scanned), DOCX files, Excel sheets, Notion exports, Obsidian vaults</strong>, and <strong>book summaries</strong>, then unifies them into <strong>clean, structured Markdown notes</strong>. These notes feed a <strong>Retrieval-Augmented Generation (RAG)</strong> pipeline, allowing an LLM to answer questions using <em>your own knowledge</em> as context â€” like a <strong>digital twin of your memory</strong>.

<h4>ğŸ§  Key use cases:</h4>
<ul>
  <li><strong>Ask questions</strong> about past notes, books, and documents</li>
  <li><strong>Navigate your Obsidian vault</strong> using natural language</li>
  <li><strong>Recall insights</strong> from PDFs and summaries you've read</li>
  <li><strong>Centralize fragmented knowledge</strong> across multiple tools</li>
  <li><strong>Build a second brain</strong> with <em>long-term memory and reasoning</em></li>
</ul>

Whether you're a <strong>researcher, writer, student, or knowledge worker</strong>, <strong>My Mind</strong> helps turn your scattered files into a <strong>cohesive, intelligent assistant</strong> â€” a <strong>searchable, contextualized reflection of how you think</strong>.
    </td>
    <td style="vertical-align: top; width: 50%">
      <img src="obsidian_notes.png" alt="Obsidian notes example" width="100%">
      <img src="pdfs_notes.png" alt="Obsidian notes example" width="100%">
    </td>
  </tr>
</table>



---
## ğŸ¯ Key Features

* âœ… Supports both **scanned** and **text-based PDFs**
* âœ… OCR powered by **EasyOCR** with GPU fallback
* âœ… Converts PDFs to images via **pdf2image**
* âœ… Intelligent file loader: detects OCR vs structured extraction
* âœ… Modular ETL folders: `extract/`, `transform/`, `load/`, `utils/`
* âœ… Saves cleaned, structured Markdown files with metadata
* âœ… Optional embedding pipeline using **LangChain + LLMs**
* âœ… Robust logging and error handling (PDF-by-PDF)
* âœ… Automatic cleanup of temporary files

---

## ğŸ—ï¸ Project Structure

```
project_root/
â”œâ”€â”€ etl/                         # ETL pipeline: extract, transform, load
â”‚   â”œâ”€â”€ extract/                 # File detection, OCR, and loading logic
â”‚   â”‚   â”œâ”€â”€ loader_files.py      # Loads structured documents (Text, Docx, Epub, etc.)
â”‚   â”‚   â”œâ”€â”€ ocr_files.py         # OCR pipeline for images and scanned PDFs
â”‚   â”‚   â””â”€â”€ smart_loader.py      # Main controller: decides between loader vs OCR
â”‚   â”‚
â”‚   â”œâ”€â”€ transform/               # Text preprocessing steps
â”‚   â”‚   â”œâ”€â”€ text_cleaner.py      # Cleans newlines, symbols, whitespace
â”‚   â”‚   â””â”€â”€ text_splitter.py     # Splits long texts into manageable chunks
â”‚   â”‚
â”‚   â”œâ”€â”€ load/                    # Output persistence and vectorization
â”‚   â”‚   â”œâ”€â”€ vector_reader.py     # Semantic search utilities
â”‚   â”‚   â”œâ”€â”€ vector_writer.py     # Optional embeddings for vector DB (FAISS, Chroma)
â”‚   â”‚
â”‚   â””â”€â”€ run_etl.py               # Main ETL runner script
â”‚
â”œâ”€â”€ data/                        # Storage for all data stages
â”‚   â”œâ”€â”€ raw/                     # Input documents (PDFs, images, etc.)
â”‚   â”œâ”€â”€ processed/               # Cleaned and intermediate text
â”‚   â””â”€â”€ output/                  # Final outputs: `.md`, `.json`, embeddings, etc.
â”‚
â”œâ”€â”€ training/                    # Optional fine-tuning support
â”‚   â”œâ”€â”€ dataset_preparation.py   # Converts extracted data into model-ready datasets
â”‚   â”œâ”€â”€ train.py                 # Fine-tunes models (e.g., LLaMA, GPT)
â”‚   â””â”€â”€ checkpoints/             # Saved model weights
â”‚
â”œâ”€â”€ inference/                   # RAG-ready inference and serving
â”‚   â”œâ”€â”€ llms/                    # Supports multiple LLMs
â”‚   â”œâ”€â”€ rag_pipeline.py          # Query + retrieval + generation logic
â”‚   â””â”€â”€ cli_app.py               # CLI or web interface (Streamlit/FastAPI)
â”‚
â”œâ”€â”€ utils/                       # Reusable helper utilities
â”‚   â”œâ”€â”€ logging_utils.py         # Custom logging helpers
â”‚   â”œâ”€â”€ directory.py             # Directory management helpers
â”‚   â”œâ”€â”€ metrics.py               # Metrics calculation and evaluation
â”‚   â””â”€â”€ sanitizers.py            # Data sanitization utilities
â”‚
â”œâ”€â”€ config/                      # Pipeline configuration
â”‚   â”œâ”€â”€ settings.py              # Centralized pipeline settings
â”‚   â”œâ”€â”€ pipeline_paths.yml       # Input/output paths for all steps
â”‚   â””â”€â”€ .env.example             # Example secrets and API keys
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for experiments
â”‚   â””â”€â”€ ocr_eval.ipynb           # OCR evaluation experiments
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # Project overview and instructions
â””â”€â”€ run.py                       # Entry point for full pipeline execution
```

---

## âš™ï¸ Getting Started

### 1. Install dependencies

```bash
git clone https://github.com/pablicio/my-mind.git
cd my-mind
pip install -r requirements.txt
```

## ğŸ” Pipeline Overview

### ğŸ“¥ Extraction (`etl/extract/`)

* Uses EasyOCR to extract text from scanned images or PDFs
* Auto-selects loader based on file type
* PDF scanned vs structured is detected dynamically
* Text files (.txt, .docx, .epub) use LangChain-compatible loaders

### ğŸ§¹ Transformation (`etl/transform/`)

* Cleans and normalizes extracted text
* Optionally splits into chunks for embedding

### ğŸ“¤ Load (`etl/load/`)

* Saves Markdown (`.md`) files with YAML frontmatter
* Optionally embeds content into FAISS or Chroma vector stores

Example Markdown output:

```markdown
---
source: example.pdf
pages: 4
processed: 2025-07-22
---

## Page 1
(Text here...)

## Page 2
(Next page...)
```

---

## ğŸ§ª Run the Pipeline

```bash
python run.py --run-extraction-exec --run-transformation-exec --run-embedding-generation-exec --run-chunk-metrics-exec --run-embedding-metrics-exec --run-inference-exec --export-settings
```

Each file will be:

1. Checked for OCR or loader-based extraction
2. Converted (if needed) to image
3. Processed and cleaned
4. Saved as `.md` (optionally embedded)

---

## ğŸ” Use Cases

* ğŸ“– Knowledge assistants over personal PDFs
* ğŸ” Semantic search for enterprise documents
* ğŸ§˜â€â™€ï¸ Life-logging and memory augmentation
* ğŸ§¾ Legal, financial, academic file indexing
* ğŸ’¬ Natural-language document Q\&A

---

## ğŸ›£ï¸ Roadmap (Phase by Phase)

### âœ… Phase 1 â€“ Document Ingestion (Completed)

* [x] Smart loader logic: decides between structured text extraction or OCR
* [x] OCR pipeline for scanned PDFs and images using EasyOCR
* [x] Loader for structured formats (.txt, .docx, .epub, etc.)

---

### âœ… Phase 2 â€“ Text Transformation

* [x] `text_cleaner.py`: Normalize text (whitespace, symbols, line breaks)
* [x] `text_splitter.py`: Split cleaned text into semantic chunks

---

### âœ… Phase 3 â€“ Output and Storage

* [x] `vector_reader.py`: Loading a previously saved vector database and performing semantic searches
* [x] `vector_writer.py`: Optional embedding generation (FAISS, Chroma, etc.)

---

### âœ… Phase 4 â€“ Inference & Retrieval
* [x] `run.py`: Call pipelines by CLI
* [x] `rag_pipeline.py`: Combine retrieval + LLM generation (RAG)
* [x] `cli_app.py`: Build a simple CLI app
* [x] `chat_app.py`: Build a Streamlit or FastAPI interface

---

### ğŸ§ª Phase 5 â€“ Testing & Evaluation

* [ ] Add unit/integration tests for each ETL stage
* [x] Performance benchmarking (OCR speed, chunk quality, embedding quality, etc.)

---

### âš™ï¸ Phase 6 â€“ Utilities and Config

* [ ] Logging and error reporting (`logging_utils.py`)
* [ ] Configuration management (`config_loader.py`, `.env`)
* [ ] File and path handling (`file_utils.py`)
* [ ] Metadata tagging and filtering logic (`sanitizers.py`)

---

### ğŸ§  Phase 7 â€“ Training (Optional)

* [ ] `dataset_preparation.py`: Convert markdown/text chunks into fine-tuning format
* [ ] `train.py`: Finetune LLMs using curated datasets
* [ ] `checkpoints/`: Save model checkpoints

---

### ğŸŒ Phase 8 â€“ UI and Integrations

* [ ] Streamlit Web UI
* [ ] File drag-and-drop upload (PDF, image, audio)
* [ ] Display OCR'd or extracted text
* [ ] Obsidian vault export for markdown outputs
* [ ] Markdown preview of final .md output

---

## ğŸ“„ License

MIT License â€” free for personal and commercial use.

---

## ğŸ¤ Contributing

PRs are welcome! For feature requests or improvements, feel free to open an issue.

---

## ğŸ‘‹ Author

Made with â¤ï¸ by \[Thiago Pablicio]
ğŸ“§ Email: [pabliciotjg@gmail.com)](mailto:pabliciotjg@gmail.com)
ğŸ”— GitHub: [github.com/pablicio](https://github.com/pablicio)
ğŸ”— LinkedIn: [Thiago Pablicio](https://www.linkedin.com/in/thiago-pablicio-86357446/)

