# ğŸ§  My Mind

## ğŸ¤– LLM-Powered PDF & Notes ETL Pipeline (Python)

**My Mind** is a modular **ETL pipeline** for extracting, cleaning, and transforming PDF documents (both digital and scanned) into structured **Markdown files**. These files can be used as contextual data for **LLM-powered applications** such as:

* Retrieval-Augmented Generation (RAG)
* Semantic search
* Personal assistants or chatbots
* Custom knowledge bases

Optimized for **personal knowledge management**, but easily extendable to **enterprise-scale document processing**.

---
## ğŸ¯ Key Features

* âœ… Supports both **scanned** and **text-based PDFs**
* âœ… OCR powered by **EasyOCR** with GPU fallback
* âœ… Converts PDFs to images via **pdf2image**
* âœ… Intelligent file loader: detects OCR vs structured extraction
* âœ… Modular ETL folders: `extract/`, `transform/`, `load/`, `utils/`
* âœ… Saves cleaned, structured Markdown files with metadata
* âœ… Optional embedding pipeline using **LangChain + OpenAI**
* âœ… Robust logging and error handling (PDF-by-PDF)
* âœ… Automatic cleanup of temporary files

---

## ğŸ—ï¸ Project Structure

```
project_root/
â”œâ”€â”€ etl/                         
â”‚   â”œâ”€â”€ extract/                 # File type detection, OCR and loader logic
â”‚   â”‚   â”œâ”€â”€ loader_files.py         # Loads structured documents (Text, Docx, Epub, etc.)
â”‚   â”‚   â”œâ”€â”€ ocr_files.py            # OCR pipeline for images and scanned PDFs
â”‚   â”‚   â””â”€â”€ smart_loader.py        # Main controller (decides loader vs OCR)
â”‚   â”‚
â”‚   â”œâ”€â”€ transform/               # Text preprocessing
â”‚   â”‚   â”œâ”€â”€ text_cleaner.py         # Cleans newlines, symbols, whitespace
â”‚   â”‚   â””â”€â”€ text_splitter.py        # Splits long texts into chunks
â”‚   â”‚
â”‚   â”œâ”€â”€ load/                    # Output persistence
â”‚   â”‚   â”œâ”€â”€ markdown_writer.py      # Saves as `.md` with metadata
â”‚   â”‚   â”œâ”€â”€ vector_writer.py        # Optional vector DB embedding (FAISS, Chroma)
â”‚   â”‚   â””â”€â”€ json_writer.py          # Optional JSON export
â”‚   â”‚
â”‚   â””â”€â”€ run_etl.py              # Main pipeline runner script
â”‚
â”œâ”€â”€ data/                       
â”‚   â”œâ”€â”€ raw/                        # Input documents (PDFs, images)
â”‚   â”œâ”€â”€ processed/                 # Cleaned intermediate texts
â”‚   â””â”€â”€ output/                    # Final `.md`, `.json`, embeddings, etc.
â”‚
â”œâ”€â”€ training/                    # Optional fine-tuning support
â”‚   â”œâ”€â”€ dataset_preparation.py      # Converts extracted data into training-ready format
â”‚   â”œâ”€â”€ train.py                    # Fine-tunes models (e.g. LLaMA, GPT)
â”‚   â””â”€â”€ checkpoints/               # Saved model weights
â”‚
â”œâ”€â”€ inference/                   # RAG-ready serving interface
â”‚   â”œâ”€â”€ rag_pipeline.py             # Query + retrieval + generation logic
â”‚   â””â”€â”€ cli_app.py                  # CLI or web interface (Streamlit/FastAPI)
â”‚
â”œâ”€â”€ utils/                       # Reusable helpers
â”‚   â”œâ”€â”€ logging_utils.py
â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â””â”€â”€ sanitizers.py
â”‚
â”œâ”€â”€ config/                     
â”‚   â”œâ”€â”€ settings.py                 # Central pipeline settings
â”‚   â””â”€â”€ .env                        # API keys and secrets
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for testing and exploration
â”‚   â””â”€â”€ ocr_eval.ipynb
â”‚
â”œâ”€â”€ requirements.txt             
â”œâ”€â”€ README.md
â””â”€â”€ main.py                      # Entry point for full pipeline execution
```

---

## âš™ï¸ Getting Started

### 1. Install dependencies

```bash
git clone https://github.com/pablicio/my-mind.git
cd my-mind
pip install -r requirements.txt
```

### 2. Set up `.env` (Optional for embeddings)

Create a `.env` file in the root folder:

```env
OPENAI_API_KEY=sk-...
```

### 3. Configure the pipeline

Edit the config file `config/settings.py`:

```python
input_dir = "input/"
output_dir = "output/"
ocr_languages = ['pt', 'en']
chunk_size = 1000
chunk_overlap = 100
```

---

## ğŸ” Pipeline Overview

### ğŸ“¥ Extraction (`etl/extract/`)

* Uses EasyOCR to extract text from scanned images or PDFs
* Auto-selects loader based on file type
* PDF scanned vs structured is detected dynamically
* Text files (.txt, .docx, .epub) use LangChain-compatible loaders

### ğŸ§¹ Transformation (`etl/transform/`)

* Cleans and normalizes extracted text
* Optionally splits into chunks for embedding

### ğŸ“¤ Load (`etl/load/`)

* Saves Markdown (`.md`) files with YAML frontmatter
* Optionally embeds content into FAISS or Chroma vector stores

Example Markdown output:

```markdown
---
source: example.pdf
pages: 4
processed: 2025-07-22
---

## Page 1
(Text here...)

## Page 2
(Next page...)
```

---

## ğŸ§ª Run the Pipeline

```bash
python main.py
```

Each file will be:

1. Checked for OCR or loader-based extraction
2. Converted (if needed) to image
3. Processed and cleaned
4. Saved as `.md` (optionally embedded)

---

## ğŸ§  Optional Embeddings (LangChain + OpenAI)

Add this to generate embeddings:

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS

embeddings = OpenAIEmbeddings()
db = FAISS.from_texts(text_chunks, embeddings)
```

---

## ğŸ” Use Cases

* ğŸ“– Knowledge assistants over personal PDFs
* ğŸ” Semantic search for enterprise documents
* ğŸ§˜â€â™€ï¸ Life-logging and memory augmentation
* ğŸ§¾ Legal, financial, academic file indexing
* ğŸ’¬ Natural-language document Q\&A

---

## ğŸ›£ï¸ Roadmap

* [ ] Whisper support for audio-based PDFs
* [ ] Web UI with file upload
* [ ] Vector DB integration (Weaviate, Pinecone, Qdrant)
* [ ] Obsidian vault export
* [ ] Metadata tagging + chunk filtering

---

## ğŸ“„ License

MIT License â€” free for personal and commercial use.

---

## ğŸ¤ Contributing

PRs are welcome! For feature requests or improvements, feel free to open an issue.

---

## ğŸ‘‹ Author

Made with â¤ï¸ by \[Thiago Pablicio]
ğŸ“§ Email: [pabliciotjg@gmail.com)](mailto:pabliciotjg@gmail.com)
ğŸ”— GitHub: [github.com/pablicio](https://github.com/pablicio)
ğŸ”— LinkedIn: [Thiago Pablicio](https://www.linkedin.com/in/thiago-pablicio-86357446/)

