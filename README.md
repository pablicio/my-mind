# My Mind

## ğŸ¤– LLM-Powered PDF & Notes ETL Pipeline (Python)

This project provides a **modular ETL pipeline** in Python that transforms raw PDF files â€” including scanned images â€” into structured Markdown files. These can be used as **contextual data sources for LLM-based systems** (e.g. retrieval-augmented generation, semantic search, assistants, or chatbots).

The system is optimized for **personal knowledge management**, but can be easily scaled to support **enterprise document processing**.


## ğŸ¯ Key Features

- âœ… Extracts text from both digital and scanned PDFs using **EasyOCR**
- âœ… Converts pages to images for OCR using **pdf2image** or **PyMuPDF**
- âœ… Cleans and normalizes text before saving it to `.md` files
- âœ… Supports recursive folder traversal
- âœ… Uses **LangChain + OpenAI** to embed content (optional)
- âœ… Modular architecture for ETL: `extract/`, `transform/`, `load/`, `utils/`, `config/`
- âœ… Automatic temporary file cleanup
- âœ… Logs errors and processes robustly, PDF-by-PDF

---

## ğŸ—ï¸ Project Structure

```
project_root/
â”œâ”€â”€ etl/                         # MÃ³dulos ETL (extraÃ§Ã£o, transformaÃ§Ã£o, carga)
â”‚   â”œâ”€â”€ extract/                 # ExtraÃ§Ã£o de dados brutos (OCR, PDF, web, etc.)
â”‚   â”‚   â”œâ”€â”€ pdf_to_image.py
â”‚   â”‚   â”œâ”€â”€ ocr_easyocr.py
â”‚   â”‚   â””â”€â”€ file_collector.py
â”‚   â”œâ”€â”€ transform/               # Limpeza, normalizaÃ§Ã£o, split de texto
â”‚   â”‚   â”œâ”€â”€ text_cleaner.py
â”‚   â”‚   â””â”€â”€ text_splitter.py
â”‚   â”œâ”€â”€ load/                    # Escrita em Markdown, JSON, vetores, etc.
â”‚   â”‚   â”œâ”€â”€ markdown_writer.py
â”‚   â”‚   â””â”€â”€ vector_store_writer.py
â”‚   â””â”€â”€ run_etl.py               # Script de orquestraÃ§Ã£o da etapa ETL
â”‚
â”œâ”€â”€ data/                        # Dados persistentes (nÃ£o versionados no Git)
â”‚   â”œâ”€â”€ raw/                     # PDFs, imagens e dados brutos
â”‚   â”œâ”€â”€ processed/               # Dados transformados
â”‚   â””â”€â”€ output/                  # SaÃ­das finais (Markdowns, JSONs, embeddings)
â”‚
â”œâ”€â”€ training/                    # Tudo relacionado a fine-tuning (opcional)
â”‚   â”œâ”€â”€ dataset_preparation.py   # ConversÃ£o para dataset de treino
â”‚   â”œâ”€â”€ train.py                 # Script de treinamento
â”‚   â””â”€â”€ checkpoints/             # Pesos treinados salvos
â”‚
â”œâ”€â”€ inference/                   # Pipelines de inferÃªncia / Q&A / RAG
â”‚   â”œâ”€â”€ rag_pipeline.py          # Busca + geraÃ§Ã£o com LLM
â”‚   â””â”€â”€ cli_app.py               # Interface de linha de comando (ou FastAPI, Streamlit etc.)
â”‚
â”œâ”€â”€ utils/                       # FunÃ§Ãµes auxiliares reutilizÃ¡veis
â”‚   â”œâ”€â”€ logging_utils.py
â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â””â”€â”€ sanitizers.py
â”‚
â”œâ”€â”€ config/                      # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ .env                     # Chaves secretas e variÃ¡veis de ambiente
â”‚
â”œâ”€â”€ notebooks/                   # Experimentos exploratÃ³rios (Jupyter)
â”‚   â””â”€â”€ ocr_eval.ipynb
â”‚
â”œâ”€â”€ requirements.txt             # DependÃªncias Python
â”œâ”€â”€ README.md
â””â”€â”€ main.py                      # Ponto de entrada principal (opcional)

````

---

## âš™ï¸ Setup Instructions

### 1. Clone and install dependencies

```bash
git clone https://github.com/pablicio/my-mind.git
cd my-mind
pip install -r requirements.txt
````

### 2. Configure your `.env` (for OpenAI, if using embeddings)

Create a `.env` file in the project root:

```
OPENAI_API_KEY=sk-...
```

### 3. Configure pipeline settings

Edit `config/settings.py` to adjust:

```python
input_dir = "input/"
output_dir = "output/"
ocr_languages = ['en', 'pt']  # EasyOCR supported languages
chunk_size = 1000             # For LangChain chunking (optional)
chunk_overlap = 100
```

---

## ğŸ§  How It Works

### ğŸ“¥ Extraction Phase (`extract/`)

* `pdf_to_image.py`: Converts every PDF page into a high-res `.png` image
* `ocr.py`: Uses EasyOCR to read text from each image

### ğŸ§¹ Transformation Phase (`transform/`)

* `text_cleaner.py`: Optional cleaning (e.g., remove artifacts, normalize unicode)

### ğŸ“¤ Load Phase (`load/`)

* `markdown_writer.py`: Writes one `.md` file per PDF with sections per page
* Output example:

  ```markdown
  ---
  pdf: my_report.pdf
  pages: 5
  ---
  ## Page 1
  (text here)
  ## Page 2
  (text here)
  ```

---

## ğŸ§ª Running the Pipeline

Use the following command to process all PDFs:

```bash
python main.py
```

Each PDF will be:

1. Converted to images
2. Processed with OCR
3. Converted into clean Markdown
4. Saved in the `/output` folder

All temporary files are cleaned up automatically.

---

## ğŸ“Œ Error Handling & Logging

* All processing steps are wrapped in `try/except` blocks.
* Errors are logged using Python's `logging` module (`pipeline.log`).
* Faulty PDFs are skipped, the pipeline continues.

---

## ğŸ”— Optional: Embedding with LangChain + OpenAI

To enable document chunking and embeddings (e.g. for vector storage):

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS

embeddings = OpenAIEmbeddings()
db = FAISS.from_texts(text_chunks, embeddings)
```

This allows the Markdown chunks to be embedded and queried in a RAG pipeline.

---

## ğŸ§  Use Cases

* ğŸ§˜ Personal LLM-powered assistants
* ğŸ“‚ Semantic search over your notes
* ğŸ“‘ Legal or HR document processors
* ğŸ¤– Enterprise knowledge bots
* ğŸ“ Structured summarization from PDFs

---

## ğŸ›£ï¸ Roadmap

* [ ] Add Whisper transcription support for audio PDFs
* [ ] Add front-end drag-and-drop web interface
* [ ] Integrate with vector DBs (Weaviate, Pinecone, Qdrant)
* [ ] Export to other formats (JSON, CSV, Obsidian vault)

---

## ğŸ“„ License

MIT License. Feel free to use, fork, and adapt.

---

## ğŸ™‹â€â™‚ï¸ Contributing

Pull requests are welcome. For major changes, open an issue first to discuss the direction.

---

## ğŸ‘‹ Contact

Made with â¤ï¸ by \[Your Name]
ğŸ“¬ Email: [your@email.com](mailto:your@email.com)
ğŸŒ Linkedin: [https://github.com/yourusername](https://github.com/yourusername)


